{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patrick Selover pselover@scu.edu #\n",
    "### CS183 Data Science Winter 2018 - Copyright @ Dr. Sukanya Manna###\n",
    "## Homework 2 ##\n",
    "**Due - 02/12/18 midnight**\n",
    "<br>The aim of this homework is to make you familiar with multiple linear regression with gradient descent optimization. You have to implement multiple linear regression from scratch using the data set provided. You can only use sklearn for evaluating your model on test data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement:** The data set for this problem originates from blog posts. The raw HTML-documents of the blog posts were crawled and processed. The prediction task associated with the data is the prediction of the number of comments in the upcoming 24 hours.\n",
    "\n",
    "In order to simulate this situation, we choose a base time (in the past) and select the blog posts that were published at most 72 hours before the selected base time. Then, we calculate all the features of the selected posts from the information that was available at the base time, therefore each instance corresponds to a blog post. *The target is the number of comments that the blog post received in the next 24 hours relative to the base time.*\n",
    "\n",
    "The training data was created based on the blogs collected in 2010 and 2011, while the test data was created based on the blogs collected in February 2012. This simulates the real-world situation in which training data from the past is available to predict events in the future.\n",
    "\n",
    "You are given [BlogFeedback Data Set](http://archive.ics.uci.edu/ml/datasets/BlogFeedback#). Please refer to this site to more about what the features are. For ease of use, I have provided here two files ``blogData_train.csv`` and ``blogData_test.csv`` to train and test your model respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Before you implement your linear regression model using gradient descent, make sure you understand your data. Perform EDA on your data to get rid of noise as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission:** Please make sure you complete this ``ipynb`` file and upload it in Camino under Assignments->hw2. Make sure your file has your ``name`` and ``email`` on top. Every step that you would work on should have comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Honor Code:** I encourage students to discuss the programming assignments including specific algorithms and data structures required for the assignments. However, students should not share any source code for solution.\n",
    "\n",
    "Code exists on the web for many problems including some that we may pose in problem sets or assignments. Students are expected to come up with the answers on their own, rather than extracting them from code on the web. This also means that we ask that you do not share your solutions to any of the homework, programming assignments, or problem sets with any other students. This includes any sort of sharing, whether face to face, by email, uploading onto public sites, etc. Doing so will drastically detract from the learning experience of your fellow students.\n",
    "\n",
    "*Please note that you are not allowed to share this homework or code anywhere (github/or any repository!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# used for dataframe use and to read in csv's\n",
    "import pandas as pd\n",
    "# used for matrix multiplication (fastest algorithm)\n",
    "import numpy as np\n",
    "import sklearn.metrics as m # you are not allowed to use sklearn's linear model for this homework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading training and test data in at same time\n",
    "df_train= pd.read_csv('blogData_train.csv',header=None)\n",
    "df_test= pd.read_csv('blogData_test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to insert cells as you need \n",
    "\n",
    "# remove very last column of table and put into y to \n",
    "# compare prediction (used for mean squared error)\n",
    "# training data\n",
    "y = df_train[df_train.columns[-1]];\n",
    "del df_train[df_train.columns[-1]];\n",
    "# test data\n",
    "RealY = df_test[df_test.columns[-1]];\n",
    "del df_test[df_test.columns[-1]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the traing data and test data\n",
    "# you have to choose an appropriate normalization function suitable for this dataset\n",
    "\n",
    "#if 1 unique value in column drop the column\n",
    "#if 2 unique values in column leave it \n",
    "#if >2 unique values in column normalize it\n",
    "for i in df_train:\n",
    "    if(df_train[i].nunique() == 1):\n",
    "#       if we remove the feature from the training data \n",
    "#       we must also remove the feature from the test data\n",
    "        del df_train[i];\n",
    "        del df_test[i];\n",
    "    elif(df_train[i].nunique() == 2):\n",
    "#       leave these features alone\n",
    "        continue;\n",
    "    else:\n",
    "#       mean normalization\n",
    "#       because the features are based on the training data's uniquness\n",
    "#       the test data has some columns that only have 1 unique element\n",
    "#       so the std() is 0 causing some features to be just NaN and if that\n",
    "#       is the case we just set it to 0\n",
    "        df_train[i] = (df_train[i] - df_train[i].mean()) / df_train[i].std();\n",
    "        df_test[i] = 0 if df_test[i].std() == 0 else (df_test[i] - df_test[i].mean()) / df_test[i].std();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cost, just a sample signature of the function is give\n",
    "# You have to complete the rest\n",
    "#   m = 276\n",
    "#   dif = (52396x276)*(276x1) -> (52396x1)-(52396x1) -> (52396x1)\n",
    "#   return = (1x52396)(52396x1) -> (1x1)/(1x1) -> 1\n",
    "\n",
    "def compute_cost(X, y, theta): \n",
    "    m = len(y);\n",
    "    dif = np.matmul(X,theta) - y;\n",
    "    return np.matmul(dif.T, dif)/(2*m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement gradient descent for multiple variables\n",
    "# a sample signature of the function is given\n",
    "# you need to complete the rest\n",
    "\n",
    "def gradient_descent_multi(X, y, alpha, iterations):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    m = len(X);\n",
    "    cost = np.zeros(iterations);\n",
    "    for i in range(iterations):\n",
    "        gradient = (1/m) * np.matmul(X.T, (np.matmul(X, theta) - y))\n",
    "        theta = theta - alpha * gradient\n",
    "#       we compute cost each iteration to determine the accuracy of the\n",
    "#       theta through each iteration\n",
    "        cost[i] = compute_cost(X,y,theta);\n",
    "    return theta,cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [-1.41651880e+00  1.95998847e+00 -4.05431120e-01  9.62604236e-01\n",
      "  1.36789863e+00  2.78706766e+00  2.70522040e+00 -5.92858823e-02\n",
      " -3.88849629e-01  3.49551064e+00  2.26862305e+00  2.68637884e+00\n",
      " -9.17417522e-01  3.66242375e+00 -2.98108548e+00 -2.27928725e+00\n",
      " -4.05431120e-01 -1.47011905e+00  9.76551125e-01  6.25508033e+00\n",
      "  3.93621752e-01 -1.96113067e+00 -2.05981669e+00  8.24292501e-01\n",
      " -1.79358478e+00  1.08257888e+00  8.74595881e-02 -8.43198561e-02\n",
      "  6.02857213e-01  1.51663884e+00 -1.72503073e-01  6.74167769e-01\n",
      " -7.78464582e-01  1.59846100e+00 -2.24037631e-01  6.50144271e-01\n",
      "  1.75615620e-01 -2.04222570e+00  6.14433845e-01  8.74595881e-02\n",
      "  1.95888011e-01 -3.51381263e-01 -5.95792220e-02 -1.10781619e+00\n",
      "  1.21656699e+00 -2.17849929e-01  1.23124138e-02 -4.20120473e+00\n",
      "  8.20189851e+00  1.97770090e+00 -3.34186183e+00  5.20161913e+00\n",
      " -1.37991490e+00  3.91963758e-01  3.24434644e-01  1.25054433e+00\n",
      "  5.25903563e-02 -3.14062938e+00  4.21953335e-01  4.68611122e-01\n",
      " -6.25990958e-01 -5.17002756e-02 -9.95723061e-03 -3.94468639e-01\n",
      "  2.61853500e-01  1.51224800e+00 -7.22747785e-01 -8.40055360e-01\n",
      "  2.18622702e+00 -5.17002756e-02 -5.13707106e-01 -8.01958409e-01\n",
      " -5.17002756e-02  3.99924989e+00 -3.66055512e-01 -1.43127793e-01\n",
      " -5.17002756e-02 -5.17002756e-02 -1.44224424e+00  7.06146457e-02\n",
      " -2.19916274e-01  8.71927531e-01 -1.33648806e-02 -2.71777823e-01\n",
      "  2.22850819e+00 -1.21366201e+00  1.70004134e-01 -1.87108045e-01\n",
      "  5.84800345e-01  8.08570188e-01 -5.17002756e-02 -1.19106189e-01\n",
      "  1.04983053e+00 -5.17002756e-02  3.78504480e-01 -1.42958581e-01\n",
      " -5.71271996e-01 -4.96641900e-01  7.69450604e-01  1.57846677e-01\n",
      "  5.98874965e-01  4.90038730e-01 -3.80920172e-01 -1.21853014e+00\n",
      " -1.30081247e+00 -4.29227882e-02 -1.28558661e+00 -3.98020522e-02\n",
      " -1.93361567e-01  1.25028775e-02 -1.15860620e+00 -2.06946530e-01\n",
      " -1.56663116e+00 -1.08472340e-01  2.34973145e-01 -1.16863562e+00\n",
      " -1.83120400e-01  5.60315500e-01 -4.40865052e-01 -2.13386705e-01\n",
      "  8.73726490e-02 -1.35036084e+00  3.24754152e-02 -1.62894375e+00\n",
      " -3.07471384e-01 -3.93327578e-02 -5.17002756e-02 -4.86142488e-01\n",
      " -5.17002756e-02  1.85414494e-01  2.90822292e-01 -8.77642423e-01\n",
      "  2.49117074e-01  1.63395505e+00  1.50324219e+00  1.96789334e-01\n",
      " -2.44308306e-01  5.27002661e-01  4.13886123e-01 -6.75777187e-01\n",
      "  6.56015833e-01 -1.69407941e+00 -8.66884406e-01 -3.13371422e+00\n",
      " -1.55472011e-01 -5.17002756e-02  4.81732034e-02  4.81520257e-01\n",
      " -6.72059981e-01 -8.69553248e-01  1.96598814e+00 -1.92115764e-01\n",
      " -5.17002756e-02  6.88269361e-02  1.00816541e+00  6.94051709e-01\n",
      " -8.53783628e-01 -5.17002756e-02 -4.71511598e-01  7.66933245e-01\n",
      " -1.08484968e+00 -6.11994468e-02 -5.17002756e-02  9.48745610e-02\n",
      " -9.84169070e-02 -5.17002756e-02 -6.49885344e-01  1.71170991e+00\n",
      " -5.17002756e-02 -1.67579145e-01 -1.25118209e+00 -1.93467906e-02\n",
      " -4.08508034e-01 -6.20457792e-01 -1.13398883e-01 -5.17002756e-02\n",
      " -3.92121564e-01 -6.96430299e-01  4.33152133e-01 -7.08569969e-01\n",
      "  6.51706693e-01 -8.05542075e-02  1.31071478e+00 -7.81047860e-01\n",
      " -7.79237317e-01 -8.07697429e-01 -5.17002756e-02 -4.89813308e-01\n",
      "  8.44942117e-01 -2.80317317e-02 -6.82514605e-01  2.53994627e+00\n",
      " -1.33183633e+00 -9.64628593e-01 -5.17002756e-02  8.09073148e-02\n",
      " -5.17002756e-02 -9.03200742e-01  6.36371338e-01 -5.32688326e-01\n",
      "  4.79732676e-02  5.79867978e-01 -3.93148365e-01  3.31858941e-01\n",
      "  1.33231189e+00 -1.91637666e-01  2.43135426e-01 -8.53203488e-01\n",
      " -5.17002756e-02  2.15637783e-02  3.06019752e-01 -1.49715408e-01\n",
      "  9.66456140e-01 -1.82724085e+00  1.02316710e+00 -1.93164251e+00\n",
      " -1.38034514e-01  1.88448197e+00 -1.68806175e+00 -7.37624192e-02\n",
      " -2.08570094e-01 -1.30652125e+00  1.26358301e+00  4.14600165e-01\n",
      " -4.08338977e-01 -1.70406886e-01  2.53135577e-01 -6.53218463e-01\n",
      "  6.84518562e-01  5.15399943e-02 -5.27511714e-01 -6.02183546e-02\n",
      " -5.17002756e-02 -1.34268219e+00 -1.01279257e+00  1.51790743e-02\n",
      " -1.86043749e-01  2.37970250e+00 -1.45607517e+00 -5.17002756e-02\n",
      " -6.66824513e-02 -4.46189924e-02 -6.82917066e-01 -6.97983363e-01\n",
      "  5.42515494e-01 -3.71172663e-02 -5.17002756e-02 -2.14672749e-01\n",
      "  1.57877185e+00 -5.66975156e-02 -3.20121766e-01 -1.57307422e+00\n",
      "  7.81221815e-03  1.12015397e+00  2.27362194e-01  1.38446079e-03\n",
      "  9.65359309e-01  1.88292283e+00 -1.01133270e-01  4.35299874e+00\n",
      "  3.26407094e+00  2.43644383e+00  2.85143522e+00  2.60144668e+00\n",
      "  3.31833625e+00  4.66231242e+00  3.26089514e+00  4.03488079e+00\n",
      "  3.53277617e+00  2.82930836e+00  3.01187431e+00  3.56494393e+00\n",
      "  3.25236540e+00  3.12645942e-02 -6.98199224e-02  9.84629282e-02]\n"
     ]
    }
   ],
   "source": [
    "# sample function calls\n",
    "\n",
    "# you have to change alpha \n",
    "# and num iteration to find out an optimal value of your theta\n",
    "it = 5000;\n",
    "theta,cost = gradient_descent_multi(df_train, y, .025, it) ;\n",
    "\n",
    "print('theta:', theta)\n",
    "# print('cost:', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost2 453.07779152370324\n"
     ]
    }
   ],
   "source": [
    "cost2 = compute_cost(df_train, y, theta)\n",
    "print('cost2', cost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Error vs. Training Epoch')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c1a3710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plots the cost function to visualize the accuracy of theta increase\n",
    "fig, ax = plt.subplots(figsize=(12,8))  \n",
    "ax.plot(np.arange(it), cost, 'r')  \n",
    "ax.set_xlabel('Iterations')  \n",
    "ax.set_ylabel('Cost')  \n",
    "ax.set_title('Error vs. Training Epoch') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test data into a dataframe\n",
    "# done above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "0     12.141054\n",
      "1      1.527472\n",
      "2      8.023187\n",
      "3      6.242879\n",
      "4      7.225567\n",
      "5     66.127296\n",
      "6     -5.109602\n",
      "7     18.283337\n",
      "8     -1.724020\n",
      "9      3.281409\n",
      "10    -0.560583\n",
      "11     2.399608\n",
      "12     3.454785\n",
      "13    30.247669\n",
      "14    26.540367\n",
      "15     7.166281\n",
      "16    14.814263\n",
      "17    -7.807079\n",
      "18    19.816982\n",
      "19    10.952197\n",
      "20    -6.564473\n",
      "21     4.531160\n",
      "22     7.410479\n",
      "23     0.434104\n",
      "24     2.579617\n",
      "25    -0.247594\n",
      "26    -0.731233\n",
      "27     0.420066\n",
      "28    13.262670\n",
      "29     2.330741\n",
      "...         ...\n",
      "7594  32.537420\n",
      "7595   4.614716\n",
      "7596  -0.366457\n",
      "7597   3.537328\n",
      "7598  -0.485395\n",
      "7599  11.387961\n",
      "7600   9.672629\n",
      "7601  -3.968560\n",
      "7602   1.798911\n",
      "7603  -3.997653\n",
      "7604   6.242014\n",
      "7605   0.605540\n",
      "7606  -4.918540\n",
      "7607   3.190688\n",
      "7608   7.087459\n",
      "7609   2.334238\n",
      "7610   8.686372\n",
      "7611  15.125015\n",
      "7612   0.650705\n",
      "7613  32.537420\n",
      "7614  -0.382090\n",
      "7615   5.279276\n",
      "7616   0.835419\n",
      "7617   2.984495\n",
      "7618 -96.842261\n",
      "7619  -3.935769\n",
      "7620   3.851026\n",
      "7621   7.800173\n",
      "7622   7.633746\n",
      "7623   3.768169\n",
      "\n",
      "[7624 rows x 1 columns] 0         4.0\n",
      "1         0.0\n",
      "2         1.0\n",
      "3         5.0\n",
      "4         0.0\n",
      "5       139.0\n",
      "6         1.0\n",
      "7         5.0\n",
      "8         2.0\n",
      "9         0.0\n",
      "10        0.0\n",
      "11        1.0\n",
      "12        0.0\n",
      "13        5.0\n",
      "14        6.0\n",
      "15        0.0\n",
      "16       22.0\n",
      "17        0.0\n",
      "18        0.0\n",
      "19        0.0\n",
      "20        0.0\n",
      "21        0.0\n",
      "22        9.0\n",
      "23        1.0\n",
      "24        0.0\n",
      "25        0.0\n",
      "26        2.0\n",
      "27        0.0\n",
      "28        1.0\n",
      "29        1.0\n",
      "        ...  \n",
      "7594      5.0\n",
      "7595      0.0\n",
      "7596      0.0\n",
      "7597      0.0\n",
      "7598      0.0\n",
      "7599     14.0\n",
      "7600      0.0\n",
      "7601      0.0\n",
      "7602      0.0\n",
      "7603      0.0\n",
      "7604      0.0\n",
      "7605      0.0\n",
      "7606      0.0\n",
      "7607      0.0\n",
      "7608      2.0\n",
      "7609      0.0\n",
      "7610      0.0\n",
      "7611      0.0\n",
      "7612      5.0\n",
      "7613      5.0\n",
      "7614      0.0\n",
      "7615      0.0\n",
      "7616      0.0\n",
      "7617      0.0\n",
      "7618      0.0\n",
      "7619      0.0\n",
      "7620      0.0\n",
      "7621      0.0\n",
      "7622      3.0\n",
      "7623      0.0\n",
      "Name: 280, Length: 7624, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Your prediction on test data\n",
    "# predict y by multiplying test features and the now acurate theta\n",
    "Pred = pd.DataFrame(np.matmul(df_test,theta))\n",
    "print(Pred, RealY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646.8194941740851"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation by scikit learn's mean_squared_error\n",
    "# note that it is acceptable if your mean_squared_error is\n",
    "# somewhere near or between 647 to 664\n",
    "m.mean_squared_error(RealY,Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
